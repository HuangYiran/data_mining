{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load package\n",
    "# string \n",
    "import re\n",
    "\n",
    "# date\n",
    "from datetime import datetime\n",
    "\n",
    "# math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import random\n",
    "\n",
    "# nlp\n",
    "from pattern.de import parse, conjugate, singularize, pluralize\n",
    "\n",
    "# sys\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# machine learning\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, gaussian_process, discriminant_analysis\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# model utils\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection \n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "# plot\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import scatter_matrix #??\n",
    "# = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline \n",
    "mpl.style.use('ggplot') #??\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8 #??\n",
    "\n",
    "# self define\n",
    "sys.path.append('../../utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ihuangyiran/anaconda2/envs/data_mining/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/ihuangyiran/anaconda2/envs/data_mining/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read files\n",
    "lb_wsp_2014 = pd.read_csv('../data/Autohaus_weeber/leonberg_werkstattposten_2014.csv', sep = ';')\n",
    "lb_wsp_2015 = pd.read_csv('../data/Autohaus_weeber/leonberg_werkstattposten_2015.csv', sep = ';')\n",
    "lb_wsp_2016 = pd.read_csv('../data/Autohaus_weeber/leonberg_werkstattposten_2016.csv', sep = ';')\n",
    "lb_wsp_2017 = pd.read_csv('../data/Autohaus_weeber/leonberg_werkstattposten_2017.csv', sep = ';')\n",
    "lb_wsp_2018 = pd.read_csv('../data/Autohaus_weeber/leonberg_werkstattposten_2018.csv', sep = ';')\n",
    "std_wsp_2014 = pd.read_csv('../data/Autohaus_weeber/weil_der_stadt_werkstattposten_2014.csv', sep = ';')\n",
    "std_wsp_2015 = pd.read_csv('../data/Autohaus_weeber/weil_der_stadt_werkstattposten_2015.csv', sep = ';')\n",
    "std_wsp_2016 = pd.read_csv('../data/Autohaus_weeber/weil_der_stadt_werkstattposten_2016.csv', sep = ';')\n",
    "std_wsp_2017 = pd.read_csv('../data/Autohaus_weeber/weil_der_stadt_werkstattposten_2017.csv', sep = ';')\n",
    "std_wsp_2018 = pd.read_csv('../data/Autohaus_weeber/weil_der_stadt_werkstattposten_2018.csv', sep = ';')\n",
    "# cat\n",
    "d1 = lb_wsp_2014.copy()\n",
    "d2 = lb_wsp_2015.copy()\n",
    "d3 = lb_wsp_2016.copy()\n",
    "d4 = lb_wsp_2017.copy()\n",
    "d5 = lb_wsp_2018.copy()\n",
    "\n",
    "d6 = std_wsp_2014.copy()\n",
    "d7 = std_wsp_2015.copy()\n",
    "d8 = std_wsp_2016.copy()\n",
    "d9 = std_wsp_2017.copy()\n",
    "d10 = std_wsp_2018.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for training we use data from 14 - 17 in lb_wsp\n",
    "train = pd.concat([d1,d2,d3,d4], 0)\n",
    "test = d5\n",
    "data = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 转化为auftrag table， 但是这次合并的是Teile-Nr项\n",
    "# 给的数据的每一行都是一个维修项，初衷是，把属于同一个auftrag的维修项合并到一起，看一下，在同一个Auftrag中，经常一起修的是那些内容\n",
    "#TODO, 这个方法的输出是一个两列的dataframe，但是一般情况下，我们会想要df中的其他属性，所以是否可以给个输出整个df的选项\n",
    "# 另外的Agg可以作为一个默认参数传入\n",
    "\n",
    "def toAuftragTable(df, att, auftn, clean = True):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df, DataFrame:\n",
    "            the dataframe\n",
    "        att, string:\n",
    "            the column name of the target attribute\n",
    "        auftn, string:\n",
    "            the column name of the aftragsnummer attribute\n",
    "        clean:\n",
    "            when true, drop the null item in auftn attribute.\n",
    "    output:\n",
    "        df_g, DataFrame:\n",
    "            dataframe contrains two columns auftn and att\n",
    "            type of item in att is string, separate with ';'\n",
    "    \"\"\"\n",
    "    # assert: make sure the type of the attributes inputted\n",
    "    \n",
    "    # extract the att and date columns\n",
    "    df = df[[att, auftn]]\n",
    "    # set type to object\n",
    "    #df[att] = df[att].astype('object')\n",
    "    #df[auftn] = df[auftn].astype('object')\n",
    "    # if clean is True, drop the fake data, like the null data\n",
    "    if clean:\n",
    "        print(\"Falls Null date exist, drop these dates directly\")\n",
    "        #df = df.drop(df[df[att].isnull()].index)\n",
    "        df = df.drop(df[df[auftn].isnull()].index)\n",
    "    # group and sum \n",
    "    df_g = df.groupby([auftn], as_index = False).apply(agg)\n",
    "    return df_g\n",
    "\n",
    "# apply 只能对单行进行处理，而不是对整个分组进行处理，所以估计应该把axis换成1，比较好\n",
    "def agg(x):\n",
    "    # 是否用‘ ’分隔会比较好，这样就不用对初始的属性，\n",
    "    # x 在这里是dataframe？？？\n",
    "    #x = [str(i) for i in x]\n",
    "    x = x.apply(lambda x: ';'.join(set([str(i) for i in x])), axis = 0)\n",
    "    #x = x.apply(lambda x: ' '.join(set(x)), axis = 0)\n",
    "    #print(x.columns.values)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FreDict:\n",
    "    \"\"\"\n",
    "    统计单词和出现的频率\n",
    "    文档中的每个字都会被记录进去，所以应该确认输入的文件内容，只含有目标列属性\n",
    "    \"\"\"\n",
    "    def __init__(self, path, header = True, sep = ';', clean = False, recover = False, singular = False):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            path: string\n",
    "                the path of the file\n",
    "            header: boolean\n",
    "                weather the file contains header of not\n",
    "            sep: string\n",
    "                the sep of the file in each line\n",
    "            clean: boolean\n",
    "                remove the word with single buchstachben or not\n",
    "            recover: boolean\n",
    "                transform 'ae', 'oe', 'ue', 'ss' back to 'ä', 'ö', 'ü', 'ß' usw.\n",
    "            singular: boolean\n",
    "                weather turns the word to singular or not\n",
    "        \"\"\"\n",
    "        self.dict_re = {'ae': 'ä', 'oe': 'ö', 'ue': 'ü', 'ß': 'ss', 'u.': 'und ', 'fzg': 'fahrzeug', ' f ': ' für '}\n",
    "        self.words, self.dict_count = self._load_data(path, header, sep, clean, recover, singular) # list of Words\n",
    "        self.ls_sorted = self._sort_dict(self.words) # list of list\n",
    "        self.len = len(self.words)\n",
    "    \n",
    "    def get_word(self, w):\n",
    "        if w in self.dict_count.keys():\n",
    "            return self.dict_count[w]\n",
    "        else:\n",
    "            return Word('x', 0, 'NAW')\n",
    "    \n",
    "    def get_best(self, s):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            s string:\n",
    "                list of words in form of string\n",
    "        output:\n",
    "            out string:\n",
    "                the frequentest word\n",
    "        \"\"\"\n",
    "        words = s.split(' ')\n",
    "        words = [word.strip() for word in words]\n",
    "        out = 'xxx'\n",
    "        count = 0\n",
    "        for word in words:\n",
    "            tmp = self.get_word(word)\n",
    "            if tmp.get_count() > count:\n",
    "                out = tmp.get_word()\n",
    "                count = tmp.get_count()\n",
    "        return out\n",
    "        \n",
    "    def top(self, n = 10):\n",
    "        # return list of list\n",
    "        # get the top n item \n",
    "        if n == -1:\n",
    "            return self.ls_sorted\n",
    "        return self.ls_sorted[:n]\n",
    "    \n",
    "    def top_norm(self, n = 10):\n",
    "        # get the top n norm\n",
    "        out = []\n",
    "        counter = 0\n",
    "        for i in self.ls_sorted:\n",
    "            if counter >= n and n != -1:\n",
    "                break\n",
    "            if i[2] == 'NN' or i[2] == 'NNP' or i[2] == 'NNS' or i[2] == 'NNPS':\n",
    "                out.append(i)\n",
    "            counter += 1\n",
    "        return out\n",
    "    \n",
    "    def top_verb(self, n = 10):\n",
    "        # get the top n verb\n",
    "        out = []\n",
    "        counter = 0\n",
    "        for i in self.ls_sorted:\n",
    "            if counter >= n and n != -1:\n",
    "                break\n",
    "            if i[2] == 'VB' or i[2] == 'VBZ' or i[2] == 'VBP' or i[2] == 'VBD' or i[2] == 'VBN' or i[2] == 'VBG':\n",
    "                out.append(i)\n",
    "            counter += 1\n",
    "        return out\n",
    "    \n",
    "    def _load_data(self, path, header, sep, clean, recover, singular):\n",
    "        \"\"\"\n",
    "        return list of words and count dictionary\n",
    "        \"\"\"\n",
    "        dic = {}\n",
    "        with open(path) as fi:\n",
    "            counter = 0\n",
    "            for li in fi:\n",
    "                # 假设句子两侧存在双引号\n",
    "                li = li.strip()\n",
    "                if li[0] == '\"':\n",
    "                    li = li[1:]\n",
    "                if li[-1] == '\"':\n",
    "                    li = li[:-1]\n",
    "                if header and counter == 0:\n",
    "                    # drop first line if header is true\n",
    "                    counter += 1\n",
    "                    continue\n",
    "                li = li.strip()\n",
    "                if recover:\n",
    "                    # recover same express if necessary\n",
    "                    for i, j in self.dict_re.items():\n",
    "                        if i in li:\n",
    "                            li = re.sub(i, j, li)\n",
    "                #items = re.split('[;, ]', li)\n",
    "                items = li.split(sep)\n",
    "                for item in items:\n",
    "                    item = item.strip()\n",
    "                    if item not in dic.keys():\n",
    "                        if clean and len(item) <= 1:\n",
    "                            # remove the item with less than 2 ziffer\n",
    "                            continue\n",
    "                        else:\n",
    "                            dic[item] = 1\n",
    "                    else:\n",
    "                        dic[item] += 1\n",
    "                counter += 1\n",
    "        # transform to Word\n",
    "        words = []\n",
    "        for i, j in dic.items():\n",
    "            try:\n",
    "                if singular:\n",
    "                    i = singularize(i).lower()\n",
    "                words.append(Word(i, j, parse(i).split('/')[1]))\n",
    "                #words.append(Word(i, j, parse(conjugate(i)).split('/')[1]))\n",
    "            except:\n",
    "                words.append(Word(i, j, ''))\n",
    "        # pack the dic\n",
    "        dic = {i: Word(i, j, parse(i).split('/')[1]) for i, j in dic.items() if len(i) > 0 }\n",
    "        # return \n",
    "        return words, dic\n",
    "    \n",
    "    def _sort_dict(self, words):\n",
    "        # return list of words, sorted according to the count\n",
    "        li_sorted = sorted(words, key = lambda x: x.get_count(), reverse = True) \n",
    "        # transform to list\n",
    "        out = []\n",
    "        for i in li_sorted:\n",
    "            out.append(i.to_list())\n",
    "        return out\n",
    "    \n",
    "class Word:\n",
    "    \"\"\"\n",
    "    use @property to rewrite the class\n",
    "    \"\"\"\n",
    "    def __init__(self, word = 'NN', count = 1, tag = 'NN'):\n",
    "        self.word = word\n",
    "        self.count = count\n",
    "        self.tag = tag\n",
    "\n",
    "    def to_list(self):\n",
    "        out = [self.word, self.count, self.tag]\n",
    "        return out\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.word + \" \" + self.count + \" \" + self.tag\n",
    "\n",
    "    def get_count(self):\n",
    "        return self.count\n",
    "\n",
    "    def get_tag(self):\n",
    "        return self.tag\n",
    "\n",
    "    def get_word(self):\n",
    "        return self.word\n",
    "\n",
    "    def set_count(self, c):\n",
    "        self.count = c\n",
    "\n",
    "    def set_tag(self, t):\n",
    "        self.tag = t\n",
    "\n",
    "    def set_word(self, w):\n",
    "        self.word = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falls Null date exist, drop these dates directly\n"
     ]
    }
   ],
   "source": [
    "df_train = toAuftragTable(train, 'Teile-Nr', 'Auftragsnummer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teile-Nr</th>\n",
       "      <th>Auftragsnummer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JLU;HDV</td>\n",
       "      <td>103K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JCR;GQQ</td>\n",
       "      <td>77KW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>WSAU000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZZ MET;LMW030000Z0;ZZ UBS;nan;D  330KD2A1</td>\n",
       "      <td>WSAU195981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W-AG-EM;N  10648301;8K0698451A;N  90813202;8K0...</td>\n",
       "      <td>WSAU198256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N  90813202;071115562C;5K6955427A;1Q1998002;na...</td>\n",
       "      <td>WSAU200129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N  0141565;SKN  0177254;1C0945511A RDW;N  9082...</td>\n",
       "      <td>WSAU200223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8E0012619;N  90813202;071115562C;03L903137A;G ...</td>\n",
       "      <td>WSAU200258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N  90813202;B  000DS;06A115561B;8E0819439;nan;...</td>\n",
       "      <td>WSAU200259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N  0209022;8P0881361G;8P0963555G;nan;W-AN-GAR</td>\n",
       "      <td>WSAU200260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4F0615301E;N  10648301;E3000;N  0138157;B  000...</td>\n",
       "      <td>WSAU200263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4E0955609;D  00950025;D  00920002;8Z0867276;D ...</td>\n",
       "      <td>WSAU200264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8E0010171S;8E0845631;8E0845099AHNVB;D  0092000...</td>\n",
       "      <td>WSAU200269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>06L115562;ZZ 07;nan;OEL02;06L103801</td>\n",
       "      <td>WSAU200270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nan;W-AG-EM;B  000DS</td>\n",
       "      <td>WSAU200272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nan;059198405;OEL02;N  0138157</td>\n",
       "      <td>WSAU200275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>W-AG-EM;N  90813202;G  060751A2;G  052164M2;OE...</td>\n",
       "      <td>WSAU200276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8K0721257A;03K131547C;03L131120A;nan;B  000750S0</td>\n",
       "      <td>WSAU200278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>N  91167901;8K0805121;N  0138157;06J115403Q;8R...</td>\n",
       "      <td>WSAU200279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1K1819653B;N  90813202;ZTW205556HD4D0;03C11556...</td>\n",
       "      <td>WSAU200286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Teile-Nr Auftragsnummer\n",
       "0                                             JLU;HDV           103K\n",
       "1                                             JCR;GQQ           77KW\n",
       "2                                                 nan     WSAU000839\n",
       "3           ZZ MET;LMW030000Z0;ZZ UBS;nan;D  330KD2A1     WSAU195981\n",
       "4   W-AG-EM;N  10648301;8K0698451A;N  90813202;8K0...     WSAU198256\n",
       "5   N  90813202;071115562C;5K6955427A;1Q1998002;na...     WSAU200129\n",
       "6   N  0141565;SKN  0177254;1C0945511A RDW;N  9082...     WSAU200223\n",
       "7   8E0012619;N  90813202;071115562C;03L903137A;G ...     WSAU200258\n",
       "8   N  90813202;B  000DS;06A115561B;8E0819439;nan;...     WSAU200259\n",
       "9       N  0209022;8P0881361G;8P0963555G;nan;W-AN-GAR     WSAU200260\n",
       "10  4F0615301E;N  10648301;E3000;N  0138157;B  000...     WSAU200263\n",
       "11  4E0955609;D  00950025;D  00920002;8Z0867276;D ...     WSAU200264\n",
       "12  8E0010171S;8E0845631;8E0845099AHNVB;D  0092000...     WSAU200269\n",
       "13                06L115562;ZZ 07;nan;OEL02;06L103801     WSAU200270\n",
       "14                               nan;W-AG-EM;B  000DS     WSAU200272\n",
       "15                     nan;059198405;OEL02;N  0138157     WSAU200275\n",
       "16  W-AG-EM;N  90813202;G  060751A2;G  052164M2;OE...     WSAU200276\n",
       "17   8K0721257A;03K131547C;03L131120A;nan;B  000750S0     WSAU200278\n",
       "18  N  91167901;8K0805121;N  0138157;06J115403Q;8R...     WSAU200279\n",
       "19  1K1819653B;N  90813202;ZTW205556HD4D0;03C11556...     WSAU200286"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there is special meaning for the nan value, it means: 手工服务\n",
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In these 'Vertrag' is the Teile-Nr empty\n",
    "#nun_auftrag_list = df_train[df_train['Teile-Nr'] == 'nan']['Auftragsnummer'].tolist()\n",
    "#num_bool = train['Auftragsnummer'].map(lambda x: True if x in nun_auftrag_list else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 看一下，Teile-Nr各个项目出现的频率\n",
    "df_train['Teile-Nr'].to_csv('/tmp/tmp.csv', sep = ';', index = False)\n",
    "dic = FreDict('/tmp/tmp.csv', header = True, sep = ';', clean = True, recover = True, singular = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nan', 72437, 'NN'],\n",
       " ['N  90813202', 11571, 'NN'],\n",
       " ['nan\"', 7103, 'NN'],\n",
       " ['G  052164DS', 6566, 'NN'],\n",
       " ['B  000DS', 6385, 'NN'],\n",
       " ['WHT000729A', 4552, 'NNP'],\n",
       " ['03L115562', 4020, 'NN'],\n",
       " ['1K1819653B', 3969, 'NN'],\n",
       " ['W-AG-EM', 3926, 'NN'],\n",
       " ['N  10648301', 3771, 'NN'],\n",
       " ['OEL02', 3758, 'NN'],\n",
       " ['N  0138157', 3155, 'NN'],\n",
       " ['SKBV18', 3115, 'NN'],\n",
       " ['000010006\"', 2837, 'CD'],\n",
       " ['OEL02\"', 2764, 'NN']]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.top(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Teile-Nr          3546\n",
       "Auftragsnummer    3546\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conbime = df_train['Teile-Nr'].map(lambda x: True if ('N  90813202' in x) and ('G  052164DS' in x) else False)\n",
    "df_train[conbime].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Teile-Nr          14755\n",
       "Auftragsnummer    14755\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_train['Teile-Nr'].map(lambda x: True if ('N  90813202' in x) else False)\n",
    "df_train[x].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Teile-Nr          8239\n",
       "Auftragsnummer    8239\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train['Teile-Nr'].map(lambda x: True if ('G  052164DS' in x) else False)\n",
    "df_train[y].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Teile-Nr          0.430392\n",
       "Auftragsnummer    0.430392\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#P(y -> x) = P(x|y) = P(x, y)/ P(y) = num_(x,y)/num_(y)\n",
    "df_train[conbime].count()/df_train[y].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 还存在的问题是：\n",
    "- 上述做法有意义的前提条件是，如果在相同vertrag中存在某个关联关系的两个物体，那么在相邻Vertrag中，也存在类似的关系。\n",
    "- 应该咨询一下，Teile-Nr能不能进行分层归类。\n",
    "- 想在这些相关关系是在同一个vertrag中出现的，但是更关心的应该是在相邻两个vertrag之间的关联关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以上是用于zwischen的例子，正式的应该通过association runle来获得，这部分内容已经在code里面实现了，所以有空直接copy过来测试就行了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "data_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
